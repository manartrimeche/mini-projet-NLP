# Legal AI Chatbot avec Llama 3.2

Ce projet implÃ©mente un systÃ¨me **Graph-RAG** (Retrieval-Augmented Generation) pour documents juridiques utilisant:

- ğŸ¦™ **Llama 3.2** comme modÃ¨le de langage
- ğŸ” **Neo4j** pour le graphe de connaissances
- ğŸ”— **LangChain** pour l'orchestration RAG
- ğŸ“š **HuggingFace** pour les embeddings

## ğŸš€ DÃ©marrage rapide

### 1. Installation des dÃ©pendances

```bash
pip install langchain langchain-community langchain_neo4j sentence-transformers pypdf transformers accelerate torch neo4j bitsandbytes tiktoken huggingface-hub
```

### 2. PrÃ©parer vos donnÃ©es

Placez vos fichiers PDF juridiques dans le dossier `data/pdfs/`:

```
mini-projet-NLP/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ pdfs/
â”‚       â”œâ”€â”€ contract1.pdf
â”‚       â”œâ”€â”€ agreement2.pdf
â”‚       â””â”€â”€ ...
```

### 3. Configurer Neo4j

Vous aurez besoin d'une instance Neo4j (gratuite sur [neo4j.com/aura](https://neo4j.com/aura)):

1. CrÃ©ez un compte Neo4j Aura
2. CrÃ©ez une nouvelle base de donnÃ©es
3. Notez vos identifiants (URI, username, password)
4. Modifiez-les dans le notebook Ã  la cellule "Configuration Neo4j"

### 4. Configurer HuggingFace

Pour accÃ©der Ã  Llama 3.2:

1. CrÃ©ez un compte sur [huggingface.co](https://huggingface.co)
2. Acceptez les conditions d'utilisation de Meta Llama sur [cette page](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)
3. CrÃ©ez un token d'accÃ¨s dans vos paramÃ¨tres HuggingFace
4. Connectez-vous dans le notebook

### 5. Lancer le notebook

Ouvrez `legal_ai_llama32.ipynb` dans VS Code ou Jupyter et exÃ©cutez les cellules dans l'ordre.

## ğŸ“‹ PrÃ©requis

### MatÃ©riel recommandÃ©:

- **GPU**: NVIDIA avec 8GB+ VRAM (pour Llama 3.2-3B)
- **RAM**: 16GB+ systÃ¨me
- **Disque**: 10GB+ espace libre

### ModÃ¨les Llama 3.2 disponibles:

| ModÃ¨le                    | VRAM     | QualitÃ©    | Recommandation     |
| ------------------------- | -------- | ---------- | ------------------ |
| Llama-3.2-1B-Instruct     | ~2GB     | Correcte   | Pour GPU limitÃ©s   |
| **Llama-3.2-3B-Instruct** | **~6GB** | **Bonne**  | **âœ… RecommandÃ©**  |
| Llama-3.2-7B-Instruct     | ~12GB    | Excellente | Pour GPU puissants |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF Docs  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Chunking  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HuggingFace Embeddings     â”‚
â”‚  (paraphrase-multilingual)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Neo4j Vector Store      â”‚
â”‚  + Knowledge Graph (NEXT)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Retrieval (Top-K)        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Llama 3.2 (4-bit)       â”‚
â”‚   Text Generation           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Answer    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ FonctionnalitÃ©s

- âœ… Chargement automatique de PDFs
- âœ… DÃ©coupage intelligent en chunks
- âœ… Embeddings multilingues
- âœ… Recherche sÃ©mantique via Neo4j
- âœ… Graphe de connaissances avec relations
- âœ… GÃ©nÃ©ration avec Llama 3.2 quantifiÃ© (4-bit)
- âœ… Historique des conversations (SQLite)
- âœ… Sources avec citations
- âœ… Interface interactive

## ğŸ“– Utilisation

### Mode Notebook

ExÃ©cutez les cellules une par une pour comprendre chaque Ã©tape.

### Mode Interactif

```python
# Dans le notebook, exÃ©cutez:
chat_loop()
```

Puis posez vos questions:

```
â“ Votre question: Quelles sont les obligations du fournisseur?
ğŸ¤– RÃ©ponse: Selon le contrat, le fournisseur doit...
```

### Questions programmatiques

```python
answer = ask_question("De quoi parle ce document?")
print(answer)
```

## ğŸ” Exemples de questions

- "De quoi traite ce document juridique?"
- "Quelles sont les principales obligations mentionnÃ©es?"
- "Quels sont les droits des parties impliquÃ©es?"
- "Quelles sont les conditions de rÃ©siliation?"
- "Quelles sont les clauses de confidentialitÃ©?"
- "Quelle est la durÃ©e du contrat?"
- "Quelles sont les pÃ©nalitÃ©s en cas de non-respect?"

## ğŸ› RÃ©solution de problÃ¨mes

### Erreur: "CUDA out of memory"

- Utilisez un modÃ¨le plus petit (Llama-3.2-1B)
- RÃ©duisez `max_length` dans `load_llm_llama32()`
- Fermez les autres applications utilisant le GPU

### Erreur: "Access denied to meta-llama"

- Acceptez les conditions d'utilisation sur HuggingFace
- VÃ©rifiez que vous Ãªtes connectÃ© avec `login()`
- Attendez quelques minutes aprÃ¨s l'acceptation

### Erreur de connexion Neo4j

- VÃ©rifiez vos identifiants
- Assurez-vous que l'URI contient `neo4j+s://` pour SSL
- Testez la connexion dans Neo4j Browser

### PDFs non chargÃ©s

- VÃ©rifiez que les PDFs sont dans `data/pdfs/`
- Assurez-vous qu'ils ne sont pas corrompus
- VÃ©rifiez les permissions de lecture

## ğŸ“Š Performance

| OpÃ©ration                        | Temps (approx) |
| -------------------------------- | -------------- |
| Chargement Llama 3.2-3B          | 2-3 min        |
| CrÃ©ation embeddings (100 chunks) | 1-2 min        |
| Ingestion Neo4j (100 chunks)     | 30 sec         |
| RequÃªte + GÃ©nÃ©ration             | 5-15 sec       |

## ğŸ” SÃ©curitÃ©

âš ï¸ **Important**:

- Ne commitez JAMAIS vos identifiants Neo4j dans Git
- Ne partagez JAMAIS votre token HuggingFace
- CrÃ©ez un fichier `.env` pour les secrets

Exemple `.env`:

```
NEO4J_URI=neo4j+s://xxxxx.databases.neo4j.io
NEO4J_USER=neo4j
NEO4J_PASSWORD=your-password
HF_TOKEN=your-huggingface-token
```

## ğŸ“š Ressources

- [Documentation Llama 3.2](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)
- [LangChain Documentation](https://python.langchain.com/)
- [Neo4j Graph Database](https://neo4j.com/docs/)
- [HuggingFace Transformers](https://huggingface.co/docs/transformers/)

## ğŸ¤ Contribution

N'hÃ©sitez pas Ã :

- Signaler des bugs
- Proposer des amÃ©liorations
- Ajouter des exemples

## ğŸ“ License

MIT License - Libre d'utilisation pour vos projets.

---

**CrÃ©Ã© avec â¤ï¸ pour le traitement intelligent de documents juridiques**
